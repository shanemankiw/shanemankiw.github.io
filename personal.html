---
permalink: /index.html
---
<!DOCTYPE html>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jionghao Wang's Homepage</title>

    <meta name="author" content="Jionghao Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Jionghao Wang">
    <link rel="stylesheet" type="text/css" href="./stylesheet.css">
    <link rel="icon" href="https://shanemankiw.github.io/images/icon.png">
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-25H6S86264"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'G-25H6S86264');
    </script>
</head>

<!-- Google tag (gtag.js) -->



<body>
    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:collapse;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:60%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Jionghao Wang</name>
                                    </p>
                                    <p>
                                        Hi! I am Jionghao Wang, you can call me John.
                                    </p>

                                    <p>
                                        I am a CS Ph.D. student at Texas A&M University, supervised by <a
                                        href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html">Prof.
                                        Wenping Wang</a> and <a href="https://people.tamu.edu/~xinli/">Prof. Xin
                                        Li</a>. 
                                        <!-- Currently, I am an intern at miHoYo(HoYoverse), Shanghai. -->
                                    </p>

                                    <p>
                                        Previously, I obtained my B.Eng. and M.Eng. degrees from Shanghai Jiao Tong University(SJTU), where I was
                                        fortunate to be supervised by <a
                                            href="https://medialab.sjtu.edu.cn/author/li-song/">Prof. Li Song</a>.
                                    </p>

                                    <!-- <p>
                                        <strong><span style="color:red;">
                                                I am actively seeking for a PhD opportunity in 2024 Fall!
                                            </span></strong>
                                        Any chance to chat would be greatly appreciated!
                                    </p> -->

                                    <p style="text-align:center">
                                        <!-- <a href="./images/WJH_CV_onepage-0907.pdf">CV</a> &nbsp;/&nbsp; -->
                                        <a href="https://scholar.google.com/citations?user=tY_XFU8AAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                                        <a href="mailto:jionghao@tamu.edu">Email</a> &nbsp;/&nbsp;
                                        <a href="https://github.com/shanemankiw">Github</a> &nbsp;/&nbsp;
                                        <a href="https://www.linkedin.com/in/jionghao-wang/">LinkedIn</a> &nbsp;/&nbsp;
                                        <a href="https://twitter.com/ShaneMankiw">Twitter</a> &nbsp;


                                        <!-- <details close="">
                                        <summary>Other Social Media</summary>
                                        <p>my wechat id: wangjionghao99</p>
                                    </details> -->
                                    </p>


                                </td>
                                <td style="padding:2.5%;width:30%;max-width:30%">
                                    <a href="https://shanemankiw.github.io/images/headshot.jpg"><img
                                            style="width:100%;max-width:100%" alt="profile photo" src="./images/headshot.jpg"
                                            class="hoverZoomLink"></a>
                                    <p></p>

                                    <p></p>
                                </td>
                            </tr>
                        </tbody>
                    </table>


                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>News</heading>
                                    <!-- <p>
                                        My current research interests lie in the intersection of 3D vision and Graphics,
                                        specifically in 3D assets generation, neural rendering, digital human, etc.
                                    </p> -->
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
                        <tbody><tr>
                          <td style="vertical-align:top">
                            <ul style="margin:0;padding-left:10px;">
                              <div style="display:grid;grid-template-columns:30px 45px auto;gap:3px;align-items:baseline;">
                                <span style="color:#888888;font-size:0.9em;font-weight:700;">OCT</span>
                                <span style="color:#888888;font-size:0.9em;font-weight:700;">2024</span>
                                <span>Attended ECCV 2024 in Milan, Italy! ðŸ‡®ðŸ‡¹</span>

                                <span style="color:#888888;font-size:0.9em;font-weight:700;">JUL</span>
                                <span style="color:#888888;font-size:0.9em;font-weight:700;">2024</span>
                                <span><a href="https://shanemankiw.github.io/SO-SMPL/">SO-SMPL</a> is accepted by ECCV 2024. Thanks to all collaborators! ðŸŽ‰</span>

                                <span style="color:#888888;font-size:0.9em;font-weight:700;">AUG</span>
                                <span style="color:#888888;font-size:0.9em;font-weight:700;">2024</span>
                                <span>Started as a Ph.D. student in Texas A&M! Gig 'em! ðŸŽ“</span>

                                <span style="color:#888888;font-size:0.9em;font-weight:700;">MAR</span>
                                <span style="color:#888888;font-size:0.9em;font-weight:700;">2024</span>
                                <span>Obtained my Masters degree from SJTU! Grateful for the amazing time! ðŸŽ“</span>

                                <span style="color:#888888;font-size:0.9em;font-weight:700;">FEB</span>
                                <span style="color:#888888;font-size:0.9em;font-weight:700;">2024</span>
                                <span>Started as a research intern at miHoYo in Shanghai! ðŸŽ®</span>
                                
                                <!-- <span style="color:#888888;font-size:0.9em;font-weight:700;">JUNE</span>
                                <span style="color:#888888;font-size:0.9em;font-weight:700;">2023</span>
                                <span>Started as a research intern with Prof. Wenping Wang and Prof. Xin Li at Texas A&M University!</span> -->
                                
                                
                              </div>
                            </ul>
                          </td>
                        </tr>
                      </tbody></table>


                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Research</heading>
                                    <!-- <p>
                                        My current research interests lie in the intersection of 3D vision and Graphics,
                                        specifically in 3D assets generation, neural rendering, digital human, etc.
                                    </p> -->
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0;border-collapse:collapse;border-spacing:0;margin-right:auto;margin-left:auto;">
                        <tbody>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/SO-SMPL.gif" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://arxiv.org/abs/2312.05295">
                                        <papertitle>Disentangled Clothed Avatar Generation from Text Descriptions
                                        </papertitle>
                                    </a>
                                    <br>
                                    <u><strong>Jionghao Wang*</strong></u>,
                                    <a href="https://liuyuan-pal.github.io/" target="_blank">Yuan Liu*</a>,
                                    <a href="https://frank-zy-dou.github.io/" target="_blank">Zhiyang Dou</a>,
                                    <a href="https://yzmblog.github.io/" target="_blank">Zhengming Yu</a>,
                                    <a href="https://lyq.me/scholar" target="_blank">Yongqing Liang</a>,
                                    <a href="https://clinplayer.github.io/" target="_blank">Cheng Lin</a>,
                                    <a href="https://medialab.sjtu.edu.cn/" target="_blank">Rong Xie</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/" target="_blank">Li Song</a>,
                                    <a href="https://people.tamu.edu/~xinli/" target="_blank">Xin Li</a>,
                                    <a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html" target="_blank">Wenping
                                    Wang</a>,

                                    <br>
                                    <em>ECCV 2024</em>
                                    <br>
                                    <a href="https://arxiv.org/abs/2312.05295">arXiv</a>
                                    /
                                    <a 
                                    href="https://shanemankiw.github.io/SO-SMPL/">Project</a>
                                    
                                    /
                                    <a
                                    href="https://github.com/shanemankiw/SO-SMPL">Github</a>
                                    <p></p>
                                    <p>
                                        In this paper, we introduced a novel text-to-avatar generation method that separately generates the human body and the clothes and allows high-quality animation on the generated avatar.
                                    </p>
                                </td>
                            </tr>
                            
                            <tr>
                                <td style="width:35%;padding:30px;padding-top:0px;" valign="top" align="center">
                                    <div style="position:relative;padding-top:56.25%;">
                                        <video style="position:absolute;top:0;left:0;width:91%;height:100%;object-fit:cover;" muted autoplay loop>
                                            <source src="images/PanoDiff.mp4" type="video/mp4">
                                            Your browser does not support the video tag.
                                        </video>
                                    </div>
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://arxiv.org/abs/2308.14686">
                                        <papertitle>360-Degree Panorama Generation from Few Unregistered NFoV Images
                                        </papertitle>
                                    </a>
                                    <br>
                                    <u><strong>Jionghao Wang*</strong></u>,
                                    <a>Ziyu Chen*</a>,
                                    <a>Jun Ling</a>,
                                    <a>Rong Xie</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>

                                    <br>
                                    <em>ACM Multimedia 2023</em>
                                    <br>
                                    <a href="https://dl.acm.org/doi/abs/10.1145/3581783.3612508">Paper</a>
                                    /
                                    <a href="https://github.com/shanemankiw/Panodiff">Github</a>
                                    /
                                    <a
                                        href="https://youtu.be/CGqEnUzpWWQ?si=KRyapkI8_2WiYDfD">Video</a>
                                    <p></p>
                                    <p>
                                        We proposed a novel diffusion-based pipeline that generates complete 360
                                        panoramas using one or more unregistered NFoV images captured from arbitrary
                                        angles.
                                    </p>
                                </td>
                            </tr>

                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/human.gif" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://ieeexplore.ieee.org/document/10211397/">
                                        <papertitle>Efficient Human Rendering with Geometric and Semantic Priors
                                        </papertitle>
                                    </a>
                                    <br>
                                    <u><strong>Jionghao Wang</strong></u>,
                                    <a>Shuai Guo</a>,
                                    <a>Qiuwen Wang</a>,
                                    <a>Rong Xie</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>
                                    <br>
                                    <em>IEEE BMSB 2023</em>
                                    <br>
                                    <a href="https://ieeexplore.ieee.org/document/10211397/">Paper</a>
                                    <p></p>
                                    <p>
                                        We propose an effective human rendering pipeline, generating geometric and
                                        semantic guidances as priors to further improve the pipeline's effectiveness and
                                        quality. In particular, a semantic human part parsing guides pixel sampling in
                                        2D space, while
                                        a mesh prior guides an occupancy field for efficient ray sampling in 3D space.
                                    </p>
                                </td>
                            </tr> -->

                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/KaiZhou.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10008839">
                                        <papertitle>RGBD-based Real-time Volumetric Reconstruction System: Architecture
                                            Design and Implementation</papertitle>
                                    </a>
                                    <br>
                                    <a>Kai Zhou</a>,
                                    <a>Shuai Guo</a>,
                                    <a>Jingchuan Hu</a>,
                                    <u><strong>Jionghao Wang</strong></u>,
                                    <a>Qiuwen Wang</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>

                                    <br>
                                    <em>VCIP '22</em>
                                    <br>
                                    <a href="https://ieeexplore.ieee.org/abstract/document/10008839">Paper</a>
                                    <p></p>
                                    <p>
                                        In this paper, a low-cost, real-time system: LiveRecon3D, is presented, with
                                        multiple RGB-D cameras connected to one single computer. The goal of the system
                                        is to provide an interactive frame rate for 3D content capture and rendering at
                                        a reduced cost.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/R100Dataset.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a href="https://dl.acm.org/doi/abs/10.1145/3524273.3532897">
                                        <papertitle>A New Free Viewpoint Video Dataset and DIBR Benchmark</papertitle>
                                    </a>
                                    <br>
                                    <a>Shuai Guo</a>,
                                    <a>Kai Zhou</a>,
                                    <a>Jingchuan Hu</a>,
                                    <u><strong>Jionghao Wang</strong></u>,
                                    <a>Jun Xu</a>,
                                    <a href="https://medialab.sjtu.edu.cn/author/li-song/">Li Song</a>

                                    <br>
                                    <em>MMSys '22</em>
                                    <br>
                                    <a href="https://dl.acm.org/doi/abs/10.1145/3524273.3532897">Paper</a>
                                    /
                                    <a
                                        href="https://github.com/sjtu-medialab/Free-Viewpoint-RGB-D-Video-Dataset">Github</a>
                                    /
                                    <a
                                        href="https://medialab.sjtu.edu.cn/post/free-viewpoint-rgb-d-video-dataset/">Post</a>
                                    <p></p>
                                    <p>
                                        In this paper, we present a new dynamic RGB-D video dataset with up to 12 views.
                                        Our dataset consists of 13 groups of dynamic video sequences, taken in the same
                                        scene.
                                    </p>
                                </td>
                            </tr> -->



                        </tbody>
                    </table>

                    <!-- <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Projects</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table> -->

                    <!-- <table
                        style="width:100%;border:0;border-collapse:collapse;border-spacing:0;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <p>
                                Below are some of my recent projects. Some older projects of mine could be found on my
                                <a href="https://github.com/shanemankiw">Github</a>.
                            </p> -->


                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/depthRefine1.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Image-Guided Kinect Depth Refinement</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We used RGB image, depth image
                                    </p>
                                </td>
                            </tr> -->

                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/DIBRlow.gif" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Depth Image Based Rendering</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We used a rather traditional Depth-Image Based Rendering algorithm, which
                                        performs interpolation by warping neighboring view RGB values to novel view
                                        based on depth values, and then blend them together. The system is optimized and
                                        can run in real-time.
                                    </p>
                                </td>
                            </tr> -->

                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/MVS.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Learning-based Multiview Stereo</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We mimicked the traditional Patchmatch-based algorithm for dense multi-view
                                        stereo with a designed deep neural network. Given neighboring view images, we
                                        estimate the dense depth value of a given view by running patchmatch modules and
                                        depth refinement
                                        modules iteratively.
                                    </p>
                                </td>
                            </tr> -->

                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/LiveScan3D.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Kinect Fusion Pipeline</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We fuse multiple Kinect sensors RGB-D inputs, generating a world-space point
                                        cloud, and refine the pipeline using masks and depth refinement. Specifically
                                        for depth refinement, we proposed to add another constraint to the classic joint
                                        bilateral kernel,
                                        and achieves better results on Kinect data.
                                    </p>
                                </td>
                            </tr> -->

                            <!-- <tr>
                                <td style="padding:30px;width:35%;vertical-align:middle;padding-top:0px">
                                    <img src="./images/MVS.png" width="200">
                                </td>
                                <td style="padding:30px;width:75%;vertical-align:middle;padding-top:0px">
                                    <a>
                                        <papertitle>Learning-based Multiview Stereo</papertitle>
                                    </a>
                                    <br>
                                    <p>
                                        We mimick the traditional Patchmatch-based algorithm for dense multi-view stereo with a deep neural network, and perform dense depth estimation for multi-view images.
                                    </p>
                                </td>
                            </tr> -->

                        <!-- </tbody>

                    </table> -->

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Education</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>
                            <!--<tr>
							<td style="padding:20px;width:25%;vertical-align:middle"><img width="100" src="./images/Cornell.png"></td>
							<td width="75%" valign="center">
							<p> Cornell University, Ph.D. in Computer Science, 2023 - 2028 (expected) </p>
							</td>
								</tr>-->
                        <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="100"
                                        src="./images/tamu.png"></td>
                                <td width="75%" valign="center">
                                    <p>Texas A&M, Ph.D. in Computer Science, 2024 -  </p>
                                </td>
                        </tr>    
			<tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="100"
                                        src="./images/sjtu.png"></td>
                                <td width="75%" valign="center">
                                    <p>SJTU, MS. in Information Engineering, EE Department, 2021 - 2024 </p>
                                    <p>Major GPA: 3.83/4 (6/70) </p>
                                    <p>TOEFL: 116/120 (Listening 30/30, Speaking 28/30) </p>
                                    <p>GRE: 329+4.5(Verbal 160 + Quantative 169 + AW 4.5) </p>
                                </td>
                            </tr>
			<tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="100"
                                        src="./images/sjtu.png"></td>
                                <td width="75%" valign="center">
                                    <p>SJTU, B.Eng. in Information Engineering, EE Department, 2017 - 2021 </p>
                                    <p>Major GPA: 89.55/100 (17/142), graduated as SJTU's Outstanding Graduate. </p>
                                </td>
                            </tr>
                            
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Experiences</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>

                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="100"
                                        src="./images/mihoyo.png"></td>
                                <td width="75%" valign="center">
                                    <p>Research Intern, miHoYo(HoYoverse) </p>
                                </td>
                            </tr>

                        </tbody>
                    </table>
                    
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>

                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="100"
                                        src="./images/tamu.png"></td>
                                <td width="75%" valign="center">
                                    <p>Research Intern, Texas A&M University</p>
                                </td>
                            </tr>

                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>

                            <tr>
                                <td style="padding:20px;width:25%;vertical-align:middle"><img width="100"
                                        src="./images/intel.png"></td>
                                <td width="75%" valign="center">
                                    <p>Media Graphics Software Engineering Intern, Intel Asia Pacific Development</p>
                                </td>
                            </tr>

                        </tbody>
                    </table>


                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Miscellaneous</heading>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                    <table width="100%" align="center" border="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td width="100%" valign="center">
                                    <p>
                                        I love comedy, sports and cinema.
                                        <!-- I am always fascinated by the beauty of cinema. During my bachelor years, I was a
                                        VP and close participant of SJTU's 800 Movie Theatre, where we held weekly movie
                                        screenings, salons, and wrote film critics. -->
                                        <!-- I also wrote several movie critics on movies such as <a href="https://www.imdb.com/title/tt0056291/"><em>NÃ³Å¼ w wodzie</em></a>, <a href="https://www.imdb.com/title/tt0087884/"><em>Paris, Texas</em></a> and <a href="https://www.imdb.com/title/tt0102943/"><em>Slackers</em></a>. -->
                                    </p>
                                    <p>
                                        I currently rank top 0.5% in the world on Yahoo Fantasy Football.
                                    </p>

                                </td>
                            </tr>
                        </tbody>
                    </table>




                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <br>
                                    <p style="text-align:right;font-size:small;">
                                        Website template borrowed from Jon Barron's personal page <a
                                            href="https://jonbarron.info/">Here</a>
                                    </p>
                                </td>
                            </tr>
                            <div class="centered-container">
                                <div style="display:inline-block;height:150px;width:150px;">
                                    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=oKSn7VbTgj_lFSs87iIr-edheQTPwSf2k4aSGq8JJiQ"></script>
                                </div>
                            </div>
                        </tbody>
                    </table>
                </td>
            </tr>
        </tbody>
    </table>

    



</body>

</html>
